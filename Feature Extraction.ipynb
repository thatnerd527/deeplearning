{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3b59d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ac467d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run createDerivation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f3434900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_vector(image: np.ndarray, final_length: int = 2048, max_features_to_detect: int = 5000) -> np.ndarray | None:\n",
    "    \"\"\"\n",
    "    Converts an image into a fixed-length 1D feature vector using ORB.\n",
    "\n",
    "    The function detects ORB features, selects the strongest ones, and flattens\n",
    "    their descriptors into a single vector.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The input image (can be color or grayscale).\n",
    "        final_length (int): The desired length of the output vector.\n",
    "                              MUST be a multiple of 32. Defaults to 1600 (50 features * 32).\n",
    "        max_features_to_detect (int): The maximum number of features for ORB to detect initially.\n",
    "                                      Should be significantly larger than (final_length / 32).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray | None: A 1D NumPy array of dtype uint8 with the specified length,\n",
    "                          or None if not enough features could be detected in the image.\n",
    "    \"\"\"\n",
    "    # 1. Validate inputs\n",
    "    if image is None:\n",
    "        print(\"Error: Input image is None.\")\n",
    "        return None\n",
    "\n",
    "    if final_length % 32 != 0:\n",
    "        raise ValueError(\"Error: final_length must be a multiple of 32.\")\n",
    "\n",
    "    # Calculate the exact number of features we need to sample\n",
    "    num_features_to_sample = final_length // 32\n",
    "\n",
    "    # 2. Ensure the image is grayscale\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_image = image # Assume it's already grayscale\n",
    "\n",
    "    # 3. Initialize ORB detector\n",
    "    orb = cv2.ORB_create(nfeatures=max_features_to_detect)\n",
    "\n",
    "    # 4. Detect keypoints and compute descriptors\n",
    "    kps, des = orb.detectAndCompute(gray_image, None)\n",
    "\n",
    "    # 5. Check if enough descriptors were found\n",
    "    if des is None or len(des) < num_features_to_sample:\n",
    "        print(f\"Warning: Found only {0 if des is None else len(des)} features, but need {num_features_to_sample}. Cannot create a vector of length {final_length}.\")\n",
    "        return None\n",
    "\n",
    "    # 6. Sort features by response score (strongest first)\n",
    "    kp_des_pairs = sorted(zip(kps, des), key=lambda x: x[0].response, reverse=True)\n",
    "\n",
    "    # 7. Select the top N features\n",
    "    top_pairs = kp_des_pairs[:num_features_to_sample]\n",
    "    \n",
    "    # We only need the descriptors from the top pairs\n",
    "    _, sampled_des = zip(*top_pairs)\n",
    "    \n",
    "    # 8. Flatten the list of descriptors into a single 1D vector\n",
    "    feature_vector = np.array(sampled_des).flatten()\n",
    "\n",
    "    return feature_vector\n",
    "def keep_all(path): return True\n",
    "def path_2_features(path: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Reads an image from the given path and converts it to a string representation of its feature vector.\n",
    "    in comma-separated format.\n",
    "    Args:\n",
    "        path (str): The file path to the image.\n",
    "    Returns:\n",
    "        str | None: A comma-separated string of the feature vector, or None if conversion fails\n",
    "    \"\"\" \n",
    "    try:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"Error: Unable to read image at path: {path}\")\n",
    "            return None\n",
    "        feature_vector = image_to_vector(img)\n",
    "        if feature_vector is None:\n",
    "            return \"0\"\n",
    "        return ','.join(map(str, feature_vector.tolist())).encode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred while processing image at path {path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7fa2e887",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_content = \"\"\n",
    "with open(\"final_variation.txt\", 'r') as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "filtered2_path = file_content.strip()\n",
    "filtered2_df = pd.read_csv(filtered2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4be3c211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Found only 6 features, but need 64. Cannot create a vector of length 2048.\n",
      "Warning: map_fn returned a string path instead of bytes for /home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_58a7481eb338b2d5/images/e0ee94654a428dfffd2ee5b77685ec36.png. Reading file content from 0.\n",
      "Warning: Found only 6 features, but need 64. Cannot create a vector of length 2048.\n",
      "Warning: map_fn returned a string path instead of bytes for /home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_58a7481eb338b2d5/images/e0ee94654a428dfffd2ee5b77685ec36.png. Reading file content from 0.\n",
      "Wrote 416 rows to /home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_ec55b06b1b0972c8/ec55b06b1b0972c8.csv (variation ec55b06b1b0972c8)\n",
      "Created variation CSV with features: /home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_ec55b06b1b0972c8/ec55b06b1b0972c8.csv\n"
     ]
    }
   ],
   "source": [
    "processed = create_dataset_variation(filtered2_df, keep_all, path_2_features, variation_tag=\"orb_features_2048\")\n",
    "print(\"Created variation CSV with features:\", processed)\n",
    "extracted_features_path = open(\"final_features.txt\", \"w\")\n",
    "extracted_features_path.write(processed)\n",
    "extracted_features_path.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
