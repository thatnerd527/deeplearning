{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0931737e",
   "metadata": {},
   "source": [
    "# Initial Modelling V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594b77c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "final_data_path = open(\"step1.txt\", \"r\")\n",
    "final_data_pre = pd.read_csv(final_data_path.read().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3203ba26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "class_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "file_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "resolution",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8856dec7-9c48-40ad-ac2e-bd09e5e4704b",
       "rows": [
        [
         "0",
         "452f2473f3dd5817395dcaa16b58ab6e.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/c6b2e678a3c50ffb73f54f5a3c0b2188.png",
         "720x1280"
        ],
        [
         "1",
         "2da7e04b024ef07fd40e4f84213d6ca7.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/eb563b39b5621d717deb668bc3b004ce.png",
         "720x1280"
        ],
        [
         "2",
         "708f00dd2a7c25d75680d18299d0254d.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/e16c6e4d4921259448d3582295b6b0cf.png",
         "720x1280"
        ],
        [
         "3",
         "866d7784b51be1f26a96af4c99e73448.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/dd0a358c11200ea325736078140a4241.png",
         "720x1280"
        ],
        [
         "4",
         "2e4fbf3ef0199cd4f664155171dbb849.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/bc55c53f29711ba656ab0c2667942360.png",
         "1280x720"
        ],
        [
         "5",
         "3a0e8525b40f6635e91227fbbb863e5b.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/948127bcdea804c274054684a6d74555.png",
         "720x1280"
        ],
        [
         "6",
         "7418a176ca85674dc59a119a769fc3d5.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/ae87e834342caca199aa2c47244807c5.png",
         "720x1280"
        ],
        [
         "7",
         "16f54be63cefa79a53279f1e805a4f3b.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/74b220ab74a396eae29b6de7ec8ee3c1.png",
         "720x1280"
        ],
        [
         "8",
         "83a3667e2cb070129e403f2e06a34300.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/3fa9f038d86f0c67ae6bedd9ec0ba7ae.png",
         "720x1280"
        ],
        [
         "9",
         "172ed312fe4f05f46d43ac6fae13be01.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/3011f66efab829118bbc75fef7fd3318.png",
         "720x1280"
        ],
        [
         "10",
         "7ac8c8fbd878f4a4081b1dbd1bade647.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/0808cf948e0e4b3568e4082352b385bb.png",
         "720x1280"
        ],
        [
         "11",
         "162bf32a3327906911080c94af983039.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/d5bcf3df69e392b87998969b4c916ad0.png",
         "720x1280"
        ],
        [
         "12",
         "22f6e062019aac76fb1aa86f12cb0097.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/0596a97254b34b68425a1a71f10fb529.png",
         "720x1280"
        ],
        [
         "13",
         "f2b7501636698afc54a960aad1f411f1.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/f68692d7814b1d9bb74e4317713e062e.png",
         "720x1280"
        ],
        [
         "14",
         "a150dda4dfa38c387bd29301265b91b2.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/8fcd06f951ba56db4ad4c7aa00ed80fb.png",
         "720x1280"
        ],
        [
         "15",
         "5fda7b3480a245806483bd52dbdb2ed0.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/3056a5919330d196477838de4c0149b9.png",
         "720x1280"
        ],
        [
         "16",
         "a426b6286c771560e8dea6d480a0763d.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/5dc09a73587a24c2975bea1fb3e36575.png",
         "1280x720"
        ],
        [
         "17",
         "cb18d6ab7371d170ef48ac8077c447d3.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/c2ff85a1811ca5657c35f8fc8f4822da.png",
         "720x1280"
        ],
        [
         "18",
         "70d36dc453bf4a490ddfbc5c91c971f4.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/5bcf70f6197b410a36116ec6eeea453d.png",
         "1280x720"
        ],
        [
         "19",
         "c0e8bb385ca49931dd7dbd3c31993458.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/7e169df7c49639694d22be8a23cde8c2.png",
         "720x1280"
        ],
        [
         "20",
         "fd6a1db9c40e83f015ffe3e7de781130.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/cfce42397d902eb09ebaded2e04b68a2.png",
         "720x1280"
        ],
        [
         "21",
         "77ef7ffaf1c488ba1d5a97950424c04d.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/8db007f43c72822ba6b228e98cf06683.png",
         "720x1280"
        ],
        [
         "22",
         "5d0005c12c916dc5eab5d3b83e54910c.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/792d7d35ecd23a0275933f51ef549fd5.png",
         "720x1280"
        ],
        [
         "23",
         "83b364c2e60cbd2acfdc21411aee7819.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/9adfe6ac3432d2ab050a6163be604a4c.png",
         "1280x720"
        ],
        [
         "24",
         "def5327d5c25e3aaedb99ff35b12f30f.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/363955cbd21e15a0bb6bb5f9a4a911a7.png",
         "720x1280"
        ],
        [
         "25",
         "32bd9112d3d1de20f17ef31d10497f04.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/53fa00ca12471a719c4257df0d11c3d4.png",
         "720x1280"
        ],
        [
         "26",
         "f446d2bf665ad39381c6cb9e353f1dec.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/627791f82253ff09b1c7387632fd44a6.png",
         "720x1280"
        ],
        [
         "27",
         "624f6b3d67001b33be04036766f0d5d6.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/32f4f7805e890e37af2dcef415f6ced5.png",
         "720x1280"
        ],
        [
         "28",
         "33c120f504148981f0f21da949592582.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/9b26ad6ae695d3fd5f9c58fe0474c079.png",
         "720x1280"
        ],
        [
         "29",
         "a52cce957294bc65e75b478d8e4b566c.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/be3c3ccba998fbd1e72bff58b5447da4.png",
         "720x1280"
        ],
        [
         "30",
         "9638b93c53883b6e69815236527cba1f.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/f9f2524a26c966761d0cb8882c6d2f49.png",
         "720x1280"
        ],
        [
         "31",
         "b6289f11a932924f55530dc872a24937.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/c01cbe0792a0a598b2d5b2659dff9a57.png",
         "720x1280"
        ],
        [
         "32",
         "8fffb73e37a72804853e88d82ca47fce.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/06310b3ebd8f63024f21bb527503e058.png",
         "720x1280"
        ],
        [
         "33",
         "45fa5760c8bdddcae29e5782d2f8602c.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/cd514f5521c8d045fe63ee19e1ef557f.png",
         "720x1280"
        ],
        [
         "34",
         "deb694ebe6cc42597b81d3a603eac07a.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/f86d4f416745a4eb46910de571c6a7dc.png",
         "720x1280"
        ],
        [
         "35",
         "924169a8cd3ccc98692c33d101d2b784.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/17fee5de8a3239cf8824ab47bd6bc01c.png",
         "720x1280"
        ],
        [
         "36",
         "2f1a0bec0b9f08f666446dc017590cf0.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/cdb8a1614c5485f58a67c7ac6f8b471b.png",
         "1280x720"
        ],
        [
         "37",
         "9eacd84502080b89dea0e2f50c98b94c.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/85131d3c722cf92a120127a9fceeecbd.png",
         "720x1280"
        ],
        [
         "38",
         "62366b7a46da9fca7ab34ba7b9cba523.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/94120861ff1d063a5b64d1f57fe6a84b.png",
         "720x1280"
        ],
        [
         "39",
         "5da367fce5ff6e470bdce96321fcdba2.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/1b75a621b5b589594a2e9418106ce9d8.png",
         "720x1280"
        ],
        [
         "40",
         "284920f5472f9204fbdd0cce4e6fbd1a.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/131e7adc2e26fb9783e8cd501023c7e4.png",
         "720x1280"
        ],
        [
         "41",
         "d388839b4ed96a48ebac4b88aafac421.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/bc42fe5d542c2a728da5b0634148a6ff.png",
         "720x1280"
        ],
        [
         "42",
         "47280b5f1d0219fb4cd84af092546af2.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/6cc7ddd80f97c6d283207e1badfc3159.png",
         "720x1280"
        ],
        [
         "43",
         "805299361c63fa67b3974cf436ed3978.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/359d9d63ea6bfede49f195b3ae745d11.png",
         "720x1280"
        ],
        [
         "44",
         "03ca9f2a4b70e718379cd3318c13b846.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/fe764152da466594f000d0e32d3ca845.png",
         "720x1280"
        ],
        [
         "45",
         "1dd1b6838cf0c6371f176752e7829802.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/2167198055655dd96760dc20bdb72aae.png",
         "720x1280"
        ],
        [
         "46",
         "9efd5b5383d20e35d617f4f895762a6b.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/fb9fe23d2e9db98aba795eb4c9748448.png",
         "720x1280"
        ],
        [
         "47",
         "4e75c70023903754bf99bae4e4cd8d81.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/55d6b52f1aa072f6f4b53b2ee0722b5f.png",
         "720x1280"
        ],
        [
         "48",
         "73252a735086a4fd94c35c20ba1499ee.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/5e84b53f6698fac207e16c75430e2e49.png",
         "1280x720"
        ],
        [
         "49",
         "917fd54f0577271c83026cb2e9f01c6e.png",
         "banana_day1_self",
         "/home/fadhlan/Normal2/DeepLearningRepo/steps/variations/var_8d36ba17d2f23fc8/images/c04ad85104506c875f3f1a27bde739dd.png",
         "720x1280"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3826
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>452f2473f3dd5817395dcaa16b58ab6e.png</td>\n",
       "      <td>banana_day1_self</td>\n",
       "      <td>/home/fadhlan/Normal2/DeepLearningRepo/steps/v...</td>\n",
       "      <td>720x1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2da7e04b024ef07fd40e4f84213d6ca7.png</td>\n",
       "      <td>banana_day1_self</td>\n",
       "      <td>/home/fadhlan/Normal2/DeepLearningRepo/steps/v...</td>\n",
       "      <td>720x1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>708f00dd2a7c25d75680d18299d0254d.png</td>\n",
       "      <td>banana_day1_self</td>\n",
       "      <td>/home/fadhlan/Normal2/DeepLearningRepo/steps/v...</td>\n",
       "      <td>720x1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>866d7784b51be1f26a96af4c99e73448.png</td>\n",
       "      <td>banana_day1_self</td>\n",
       "      <td>/home/fadhlan/Normal2/DeepLearningRepo/steps/v...</td>\n",
       "      <td>720x1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2e4fbf3ef0199cd4f664155171dbb849.png</td>\n",
       "      <td>banana_day1_self</td>\n",
       "      <td>/home/fadhlan/Normal2/DeepLearningRepo/steps/v...</td>\n",
       "      <td>1280x720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3821</th>\n",
       "      <td>2790a53203bb55d957f3d51eb8161592.png</td>\n",
       "      <td>avocado_firm_google</td>\n",
       "      <td>/home/fadhlan/Normal2/DeepLearningRepo/steps/v...</td>\n",
       "      <td>730x548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>d8891a6e393c829c349241f4baac8ad5.png</td>\n",
       "      <td>avocado_firm_google</td>\n",
       "      <td>/home/fadhlan/Normal2/DeepLearningRepo/steps/v...</td>\n",
       "      <td>800x378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823</th>\n",
       "      <td>244c532e45a81497e3d51e81a1fcb04d.png</td>\n",
       "      <td>avocado_firm_google</td>\n",
       "      <td>/home/fadhlan/Normal2/DeepLearningRepo/steps/v...</td>\n",
       "      <td>872x534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824</th>\n",
       "      <td>8109576227fc9d3f8e5b74db76b4da70.png</td>\n",
       "      <td>avocado_firm_google</td>\n",
       "      <td>/home/fadhlan/Normal2/DeepLearningRepo/steps/v...</td>\n",
       "      <td>480x360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>8d52aec527115a5fec609bab5c43d406.png</td>\n",
       "      <td>avocado_firm_google</td>\n",
       "      <td>/home/fadhlan/Normal2/DeepLearningRepo/steps/v...</td>\n",
       "      <td>600x400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3826 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id           class_name  \\\n",
       "0     452f2473f3dd5817395dcaa16b58ab6e.png     banana_day1_self   \n",
       "1     2da7e04b024ef07fd40e4f84213d6ca7.png     banana_day1_self   \n",
       "2     708f00dd2a7c25d75680d18299d0254d.png     banana_day1_self   \n",
       "3     866d7784b51be1f26a96af4c99e73448.png     banana_day1_self   \n",
       "4     2e4fbf3ef0199cd4f664155171dbb849.png     banana_day1_self   \n",
       "...                                    ...                  ...   \n",
       "3821  2790a53203bb55d957f3d51eb8161592.png  avocado_firm_google   \n",
       "3822  d8891a6e393c829c349241f4baac8ad5.png  avocado_firm_google   \n",
       "3823  244c532e45a81497e3d51e81a1fcb04d.png  avocado_firm_google   \n",
       "3824  8109576227fc9d3f8e5b74db76b4da70.png  avocado_firm_google   \n",
       "3825  8d52aec527115a5fec609bab5c43d406.png  avocado_firm_google   \n",
       "\n",
       "                                              file_path resolution  \n",
       "0     /home/fadhlan/Normal2/DeepLearningRepo/steps/v...   720x1280  \n",
       "1     /home/fadhlan/Normal2/DeepLearningRepo/steps/v...   720x1280  \n",
       "2     /home/fadhlan/Normal2/DeepLearningRepo/steps/v...   720x1280  \n",
       "3     /home/fadhlan/Normal2/DeepLearningRepo/steps/v...   720x1280  \n",
       "4     /home/fadhlan/Normal2/DeepLearningRepo/steps/v...   1280x720  \n",
       "...                                                 ...        ...  \n",
       "3821  /home/fadhlan/Normal2/DeepLearningRepo/steps/v...    730x548  \n",
       "3822  /home/fadhlan/Normal2/DeepLearningRepo/steps/v...    800x378  \n",
       "3823  /home/fadhlan/Normal2/DeepLearningRepo/steps/v...    872x534  \n",
       "3824  /home/fadhlan/Normal2/DeepLearningRepo/steps/v...    480x360  \n",
       "3825  /home/fadhlan/Normal2/DeepLearningRepo/steps/v...    600x400  \n",
       "\n",
       "[3826 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d59d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 09:22:11.371476: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765876933.733459 2059581 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1212 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "final_data_pre = final_data_pre[final_data_pre[\"class_name\"].str.contains(\"banana\") & ~final_data_pre[\"class_name\"].str.contains(\"google\")]\n",
    "\n",
    "label_processor = tf.keras.layers.StringLookup(\n",
    "    output_mode='int', vocabulary=final_data_pre['class_name'].unique(),\n",
    "    num_oov_indices=0,\n",
    "    mask_token=None\n",
    ")\n",
    "\n",
    "def load_image(filepath, label):\n",
    "    img = tf.io.read_file(filepath)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [224, 224])\n",
    "    return img, label\n",
    "\n",
    "\n",
    "# --- 4. ASSEMBLE THE DATASET ---\n",
    "\n",
    "# Create dataset from DataFrame columns\n",
    "dataset = tf.data.Dataset.from_tensor_slices((final_data_pre['file_path'].values, final_data_pre['class_name'].values))\n",
    "# Convert string to int\n",
    "dataset = dataset.map(lambda x, y: (x, label_processor(y)))\n",
    "# Load the image using tensorflow as an image array\n",
    "dataset = dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
    "dataset = dataset.batch(64).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6effa05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"unified_res_net_classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"unified_res_net_classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 09:22:28.711083: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f6aa40a31e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-12-16 09:22:28.711110: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4060, Compute Capability 8.9\n",
      "2025-12-16 09:22:28.936927: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-12-16 09:22:30.238463: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n",
      "2025-12-16 09:22:30.329957: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-12-16 09:22:30.329982: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-12-16 09:22:30.330008: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-12-16 09:22:30.330016: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-12-16 09:22:30.330042: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-12-16 09:22:30.330050: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-12-16 09:22:31.717346: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5099', 312 bytes spill stores, 312 bytes spill loads\n",
      "\n",
      "2025-12-16 09:22:32.738469: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5106', 176 bytes spill stores, 176 bytes spill loads\n",
      "\n",
      "2025-12-16 09:22:33.988425: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7999', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-12-16 09:22:34.070622: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8001', 944 bytes spill stores, 944 bytes spill loads\n",
      "\n",
      "2025-12-16 09:22:34.189235: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8001', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-12-16 09:22:34.526585: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5319', 312 bytes spill stores, 312 bytes spill loads\n",
      "\n",
      "2025-12-16 09:22:34.791946: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7999', 1340 bytes spill stores, 1340 bytes spill loads\n",
      "\n",
      "2025-12-16 09:22:38.058852: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 17s/step - accuracy: 0.0000e+00 - loss: 2.3806"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765876960.320887 2059667 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.0162 - loss: 2.3123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 09:22:42.399232: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5099', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-12-16 09:22:44.387477: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.1137 - loss: 2.1815 \n",
      "Epoch 2/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.1983 - loss: 1.9872 \n",
      "Epoch 3/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.2187 - loss: 1.9222\n",
      "Epoch 4/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.2653 - loss: 1.8828\n",
      "Epoch 5/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.2711 - loss: 1.8502\n",
      "Epoch 6/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.3003 - loss: 1.8272\n",
      "Epoch 7/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.3149 - loss: 1.8047\n",
      "Epoch 8/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.3382 - loss: 1.7766\n",
      "Epoch 9/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.4023 - loss: 1.7388\n",
      "Epoch 10/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.4227 - loss: 1.6982 \n",
      "Epoch 11/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.4490 - loss: 1.6649\n",
      "Epoch 12/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.4869 - loss: 1.6341\n",
      "Epoch 13/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.5015 - loss: 1.5973\n",
      "Epoch 14/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.4956 - loss: 1.5594\n",
      "Epoch 15/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5248 - loss: 1.5213\n",
      "Epoch 16/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5364 - loss: 1.4830\n",
      "Epoch 17/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5539 - loss: 1.4497\n",
      "Epoch 18/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.5627 - loss: 1.4082\n",
      "Epoch 19/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5860 - loss: 1.3710\n",
      "Epoch 20/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.5918 - loss: 1.3416 \n"
     ]
    }
   ],
   "source": [
    "%run modeldef2.py\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_CLASSES = len(final_data_pre['class_name'].unique())\n",
    "\n",
    "# Create the Unified Model\n",
    "model = UnifiedResNetClassifier(num_classes=NUM_CLASSES)\n",
    "model.summary()\n",
    "\n",
    "# Compile\n",
    "# We use from_logits=True because the final layer has no Softmax\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2859a10d",
   "metadata": {},
   "source": [
    "### As seen in the epoch results, the model isnt performing too well, with an accuracy of 0.548 and a loss of 1.49, it seems to be quite high. So for the next iteration of the processing pipeline, more augmentations and hyperparameter optimizations will be done to increase the model's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7608790a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
