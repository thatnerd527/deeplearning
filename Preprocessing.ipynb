{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716288a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "STEPS = \"./steps\"\n",
    "if not os.path.isdir(STEPS):\n",
    "    os.mkdir(STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4446e287",
   "metadata": {},
   "source": [
    "# Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1eb2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9b79855",
   "metadata": {},
   "source": [
    "## Segment all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7f4aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING yolo_nas_l.pt appears to require 'super_gradients', which is not in Ultralytics requirements.\n",
      "AutoInstall will run now for 'super_gradients' but this feature will be removed in the future.\n",
      "Recommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official Ultralytics model, i.e. 'yolo predict model=yolo11n.pt'\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['super_gradients'] not found, attempting AutoUpdate...\n",
      "WARNING Retry 1/2 failed: Command 'pip install --no-cache-dir \"super_gradients\" ' returned non-zero exit status 1.\n",
      "WARNING Retry 2/2 failed: Command 'pip install --no-cache-dir \"super_gradients\" ' returned non-zero exit status 1.\n",
      "WARNING \u001b[31m\u001b[1mrequirements:\u001b[0m  Command 'pip install --no-cache-dir \"super_gradients\" ' returned non-zero exit status 1.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'super_gradients'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\miniconda3\\envs\\DeepLearning\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1448\u001b[39m, in \u001b[36mtorch_safe_load\u001b[39m\u001b[34m(weight, safe_only)\u001b[39m\n\u001b[32m   1447\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m             ckpt = \u001b[43mtorch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\miniconda3\\envs\\DeepLearning\\Lib\\site-packages\\ultralytics\\utils\\patches.py:120\u001b[39m, in \u001b[36mtorch_load\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    118\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\miniconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\serialization.py:1530\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1529\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1530\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1531\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1532\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1533\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1534\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1535\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\miniconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\serialization.py:2119\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   2118\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m2119\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2120\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\miniconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\serialization.py:2108\u001b[39m, in \u001b[36m_load.<locals>.UnpicklerWrapper.find_class\u001b[39m\u001b[34m(self, mod_name, name)\u001b[39m\n\u001b[32m   2107\u001b[39m mod_name = load_module_mapping.get(mod_name, mod_name)\n\u001b[32m-> \u001b[39m\u001b[32m2108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'super_gradients'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 1. Load the best model\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# The .pt file will be downloaded automatically on the first run.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myolo_nas_l.pt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 2. Load your image\u001b[39;00m\n\u001b[32m     10\u001b[39m image_path = \u001b[33m\"\u001b[39m\u001b[33m20250926_142509.jpg\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# <-- Change to your image file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\miniconda3\\envs\\DeepLearning\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:83\u001b[39m, in \u001b[36mYOLO.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m = new_instance.\u001b[34m__dict__\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mRTDETR\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.model[-\u001b[32m1\u001b[39m]._get_name():  \u001b[38;5;66;03m# if RTDETR head\u001b[39;00m\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\miniconda3\\envs\\DeepLearning\\Lib\\site-packages\\ultralytics\\engine\\model.py:153\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m._new(model, task=task, verbose=verbose)\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\miniconda3\\envs\\DeepLearning\\Lib\\site-packages\\ultralytics\\engine\\model.py:297\u001b[39m, in \u001b[36mModel._load\u001b[39m\u001b[34m(self, weights, task)\u001b[39m\n\u001b[32m    294\u001b[39m weights = checks.check_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights).rpartition(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.ckpt = \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     \u001b[38;5;28mself\u001b[39m.task = \u001b[38;5;28mself\u001b[39m.model.task\n\u001b[32m    299\u001b[39m     \u001b[38;5;28mself\u001b[39m.overrides = \u001b[38;5;28mself\u001b[39m.model.args = \u001b[38;5;28mself\u001b[39m._reset_ckpt_args(\u001b[38;5;28mself\u001b[39m.model.args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\miniconda3\\envs\\DeepLearning\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1501\u001b[39m, in \u001b[36mload_checkpoint\u001b[39m\u001b[34m(weight, device, inplace, fuse)\u001b[39m\n\u001b[32m   1487\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_checkpoint\u001b[39m(weight, device=\u001b[38;5;28;01mNone\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m, fuse=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1488\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1489\u001b[39m \u001b[33;03m    Load a single model weights.\u001b[39;00m\n\u001b[32m   1490\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1499\u001b[39m \u001b[33;03m        ckpt (dict): Model checkpoint dictionary.\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1501\u001b[39m     ckpt, weight = \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[32m   1502\u001b[39m     args = {**DEFAULT_CFG_DICT, **(ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mtrain_args\u001b[39m\u001b[33m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[32m   1503\u001b[39m     model = (ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mema\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]).float()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\miniconda3\\envs\\DeepLearning\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1474\u001b[39m, in \u001b[36mtorch_safe_load\u001b[39m\u001b[34m(weight, safe_only)\u001b[39m\n\u001b[32m   1467\u001b[39m     LOGGER.warning(\n\u001b[32m   1468\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m appears to require \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, which is not in Ultralytics requirements.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1469\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAutoInstall will run now for \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m but this feature will be removed in the future.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1470\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRecommend fixes are to train a new model using the latest \u001b[39m\u001b[33m'\u001b[39m\u001b[33multralytics\u001b[39m\u001b[33m'\u001b[39m\u001b[33m package or to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1471\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrun a command with an official Ultralytics model, i.e. \u001b[39m\u001b[33m'\u001b[39m\u001b[33myolo predict model=yolo11n.pt\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1472\u001b[39m     )\n\u001b[32m   1473\u001b[39m     check_requirements(e.name)  \u001b[38;5;66;03m# install missing module\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1474\u001b[39m     ckpt = \u001b[43mtorch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ckpt, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m   1477\u001b[39m     \u001b[38;5;66;03m# File is likely a YOLO instance saved with i.e. torch.save(model, \"saved_model.pt\")\u001b[39;00m\n\u001b[32m   1478\u001b[39m     LOGGER.warning(\n\u001b[32m   1479\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe file \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m appears to be improperly saved or formatted. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1480\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFor optimal results, use model.save(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mfilename.pt\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) to correctly save YOLO models.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1481\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\miniconda3\\envs\\DeepLearning\\Lib\\site-packages\\ultralytics\\utils\\patches.py:120\u001b[39m, in \u001b[36mtorch_load\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    118\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\miniconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\serialization.py:1530\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1528\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1529\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1530\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1531\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1532\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1533\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1534\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1535\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[32m   1538\u001b[39m     f_name = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\miniconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\serialization.py:2119\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   2117\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   2118\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m2119\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2120\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2122\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\miniconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\serialization.py:2108\u001b[39m, in \u001b[36m_load.<locals>.UnpicklerWrapper.find_class\u001b[39m\u001b[34m(self, mod_name, name)\u001b[39m\n\u001b[32m   2106\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   2107\u001b[39m mod_name = load_module_mapping.get(mod_name, mod_name)\n\u001b[32m-> \u001b[39m\u001b[32m2108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'super_gradients'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the best model\n",
    "# The .pt file will be downloaded automatically on the first run.\n",
    "model = YOLO('yolo11x-seg.pt')\n",
    "\n",
    "# 2. Load your image\n",
    "image_path = \"20250926_142509.jpg\" # <-- Change to your image file\n",
    "original_image = cv2.imread(image_path)\n",
    "\n",
    "# 3. Run prediction\n",
    "results = model(original_image, device='0')\n",
    "\n",
    "# The result object contains all the segmentation data\n",
    "result = results[0]\n",
    "# Check if any masks were detected\n",
    "if result.masks is not None:\n",
    "    # 4. Loop through each detected object\n",
    "    for i, mask in enumerate(result.masks.data):\n",
    "\n",
    "        # Get the class name\n",
    "        class_id = int(result.boxes.cls[i])\n",
    "        class_name = model.names[class_id]\n",
    "\n",
    "        print(f\"Extracting object {i+1}: {class_name}\")\n",
    "\n",
    "        # Convert mask to a binary image (0 or 255) and resize to original image size\n",
    "        binary_mask = mask.cpu().numpy().astype(np.uint8) * 255\n",
    "        binary_mask = cv2.resize(binary_mask, (original_image.shape[1], original_image.shape[0]))\n",
    "        \n",
    "        # 5. Create a transparent RGBA image for the extracted object\n",
    "        extracted_rgba = cv2.cvtColor(original_image, cv2.COLOR_BGR2BGRA)\n",
    "        extracted_rgba[:, :, 3] = binary_mask # Set the alpha channel\n",
    "        \n",
    "        # Save the extracted object\n",
    "        output_filename = f\"extracted_{class_name}_{i+1}.png\"\n",
    "        cv2.imwrite(output_filename, extracted_rgba)\n",
    "\n",
    "    print(f\"\\nSuccessfully extracted {len(result.masks.data)} objects.\")\n",
    "else:\n",
    "    print(\"No objects were segmented in the image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b448313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\FastProjects\\DeepLearningRepo\\image.jpg: 640x480 1 apple, 1 dining table, 36.9ms\n",
      "Speed: 3.1ms preprocess, 36.9ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mC:\\FastProjects\\DeepLearningRepo\\runs\\segment\\predict\u001b[0m\n",
      "Found 2 objects with masks.\n",
      "\n",
      "Segmentation complete! Check the 'runs/segment/predict' folder for the output image.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "# 1. Load a pre-trained segmentation model\n",
    "# The 'yolov8n-seg.pt' is a small and fast segmentation model.\n",
    "# Other options include yolov8s-seg.pt, yolov8m-seg.pt, etc.\n",
    "model = YOLO('yolo11x-seg.pt')\n",
    "\n",
    "# 2. Define the image you want to process\n",
    "source_image = 'https://ultralytics.com/images/bus.jpg' # You can use a URL or a local path\n",
    "\n",
    "# 3. Run inference with hardware acceleration\n",
    "# Specify device='cuda' for NVIDIA GPUs or device='mps' for Apple Silicon.\n",
    "# You can also use a specific GPU like device=0.\n",
    "results = model.predict(source=\"image.jpg\", device='cuda', save=True)\n",
    "\n",
    "# 4. Process results (optional)\n",
    "# The 'results' object contains all the information.\n",
    "# For segmentation, you can access the masks.\n",
    "if results[0].masks:\n",
    "    print(f\"Found {len(results[0].masks)} objects with masks.\")\n",
    "    # You can access mask data via results[0].masks.data\n",
    "else:\n",
    "    print(\"No segmentation masks were found.\")\n",
    "\n",
    "# The predicted image with masks will be saved in a 'runs/segment/predict' directory.\n",
    "print(\"\\nSegmentation complete! Check the 'runs/segment/predict' folder for the output image.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
